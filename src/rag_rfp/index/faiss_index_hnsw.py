import numpy as np
import faiss
import time
from tqdm import tqdm
# ë©”íƒ€ë°ì´í„° ë¡œë“œ ì¶”ê°€
import pickle

with open("metadata.pkl", "rb") as f:
    metadata = pickle.load(f)

print(f"âœ… ë©”íƒ€ë°ì´í„° ë¡œë“œ: {len(metadata)}ê°œ")
# ê¸°ì¡´ ì„ë² ë”© ë¡œë“œ
embeddings = np.load("embeddings.npy")
dim = embeddings.shape[1]
n_vectors = embeddings.shape[0]

def create_multiple_indexes(embeddings):
    """ë‹¤ì–‘í•œ FAISS ì¸ë±ìŠ¤ ìƒì„±"""
    indexes = {}
    
    print(f"Creating indexes for {n_vectors:,} vectors, {dim}D")
    
    # 1. IndexFlatIP (í˜„ì¬ ì‚¬ìš©ì¤‘ - ë² ì´ìŠ¤ë¼ì¸)
    print("1. IndexFlatIP (Exact Inner Product)")
    start_time = time.time()
    index_flat_ip = faiss.IndexFlatIP(dim)
    index_flat_ip.add(embeddings)
    indexes['FlatIP'] = {
        'index': index_flat_ip,
        'build_time': time.time() - start_time,
        'type': 'exact'
    }
    
    # 2. IndexFlatL2 (ì •í™•í•œ L2 ê±°ë¦¬)
    print("2. IndexFlatL2 (Exact L2 Distance)")
    start_time = time.time()
    index_flat_l2 = faiss.IndexFlatL2(dim)
    index_flat_l2.add(embeddings)
    indexes['FlatL2'] = {
        'index': index_flat_l2,
        'build_time': time.time() - start_time,
        'type': 'exact'
    }
    
    # 3. IndexIVFFlat (ê·¼ì‚¬ ê²€ìƒ‰)
    print("3. IndexIVFFlat (Approximate)")
    nlist = min(4 * int(np.sqrt(n_vectors)), n_vectors // 39)  # í´ëŸ¬ìŠ¤í„° ìˆ˜
    quantizer = faiss.IndexFlatIP(dim)
    start_time = time.time()
    index_ivf = faiss.IndexIVFFlat(quantizer, dim, nlist, faiss.METRIC_INNER_PRODUCT)
    index_ivf.train(embeddings)
    index_ivf.add(embeddings)
    index_ivf.nprobe = min(nlist // 4, 50)  # ê²€ìƒ‰í•  í´ëŸ¬ìŠ¤í„° ìˆ˜
    indexes['IVFFlat'] = {
        'index': index_ivf,
        'build_time': time.time() - start_time,
        'type': 'approximate',
        'nlist': nlist,
        'nprobe': index_ivf.nprobe
    }
    
    # 4. IndexIVFPQ (ì••ì¶• + ê·¼ì‚¬)
    print("4. IndexIVFPQ (Compressed + Approximate)")
    m = 64  # PQ ì„œë¸Œë²¡í„° ìˆ˜
    nbits = 8  # ë¹„íŠ¸ ìˆ˜
    start_time = time.time()
    index_ivfpq = faiss.IndexIVFPQ(quantizer, dim, nlist, m, nbits)
    index_ivfpq.train(embeddings)
    index_ivfpq.add(embeddings)
    index_ivfpq.nprobe = min(nlist // 4, 50)
    indexes['IVFPQ'] = {
        'index': index_ivfpq,
        'build_time': time.time() - start_time,
        'type': 'compressed',
        'nlist': nlist,
        'nprobe': index_ivfpq.nprobe,
        'm': m,
        'nbits': nbits
    }
    
    # 5. IndexHNSWFlat (ê³ ì† ê·¼ì‚¬)
    print("5. IndexHNSWFlat (Fast Approximate)")
    M = 32  # ì—°ê²° ìˆ˜
    start_time = time.time()
    index_hnsw = faiss.IndexHNSWFlat(dim, M)
    index_hnsw.hnsw.efConstruction = 200
    index_hnsw.add(embeddings)
    index_hnsw.hnsw.efSearch = 128
    indexes['HNSW'] = {
        'index': index_hnsw,
        'build_time': time.time() - start_time,
        'type': 'graph',
        'M': M,
        'efConstruction': 200,
        'efSearch': 128
    }
    
    return indexes

def benchmark_indexes(indexes, query_embeddings, k=5):
    """ì¸ë±ìŠ¤ë³„ ì„±ëŠ¥ ì¸¡ì •"""
    results = {}
    
    for name, index_info in indexes.items():
        print(f"\nğŸ” Testing {name}...")
        
        index = index_info['index']
        search_times = []
        
        # ê²€ìƒ‰ ì‹œê°„ ì¸¡ì •
        for query_emb in tqdm(query_embeddings, desc=f"{name} search"):
            start_time = time.time()
            D, I = index.search(query_emb.reshape(1, -1), k)
            search_times.append(time.time() - start_time)
        
        avg_search_time = np.mean(search_times)
        qps = len(query_embeddings) / sum(search_times)  # Queries Per Second
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì • (ìˆ˜ì •ëœ ë¶€ë¶„)
        try:
            # FAISS ì¸ë±ìŠ¤ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°
            if name == 'FlatIP' or name == 'FlatL2':
                # Flat ì¸ë±ìŠ¤: ì „ì²´ ë²¡í„° ì €ì¥
                memory_mb = (n_vectors * dim * 4) / (1024**2)  # float32
            elif 'IVF' in name:
                # IVF ì¸ë±ìŠ¤: í´ëŸ¬ìŠ¤í„° + ë²¡í„°
                nlist = index_info.get('nlist', 100)
                if 'PQ' in name:
                    # PQ ì••ì¶•ëœ ê²½ìš°
                    m = index_info.get('m', 64)
                    memory_mb = (n_vectors * m + nlist * dim * 4) / (1024**2)
                else:
                    # IVFFlat
                    memory_mb = (n_vectors * dim * 4 + nlist * dim * 4) / (1024**2)
            elif name == 'HNSW':
                # HNSW: ë²¡í„° + ê·¸ë˜í”„ êµ¬ì¡°
                M = index_info.get('M', 32)
                memory_mb = (n_vectors * (dim * 4 + M * 4)) / (1024**2)
            else:
                # ê¸°ë³¸ê°’
                memory_mb = (n_vectors * dim * 4) / (1024**2)
                
        except Exception as e:
            print(f"   âš ï¸ ë©”ëª¨ë¦¬ ê³„ì‚° ì˜¤ë¥˜: {e}")
            memory_mb = (n_vectors * dim * 4) / (1024**2)  # ê¸°ë³¸ê°’
        
        results[name] = {
            'avg_search_time_ms': avg_search_time * 1000,
            'qps': qps,
            'build_time_sec': index_info['build_time'],
            'memory_mb': memory_mb,
            'type': index_info['type']
        }
        
        print(f"   â±ï¸  í‰ê·  ê²€ìƒ‰ì‹œê°„: {avg_search_time*1000:.2f}ms")
        print(f"   ğŸš€ QPS: {qps:.1f}")
        print(f"   ğŸ—ï¸  ë¹Œë“œ ì‹œê°„: {index_info['build_time']:.2f}ì´ˆ")
        print(f"   ğŸ’¾ ë©”ëª¨ë¦¬: {memory_mb:.1f}MB")
    
    return results


def measure_recall_accuracy(indexes, evaluation_queries, metadata, model, k_values=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]):
    """ì¸ë±ìŠ¤ë³„ Recall ì •í™•ë„ ì¸¡ì • (R@1~10)"""
    recall_results = {}
    
    for index_name, index_info in indexes.items():
        print(f"\nğŸ“Š Measuring recall for {index_name}...")
        
        index = index_info['index']
        recalls = {f'R@{k}': 0 for k in k_values}
        
        for query_data in tqdm(evaluation_queries, desc=f"{index_name} recall"):
            query_text = query_data['question']
            gt_doc_id = query_data['gt_doc_id']
            
            # ì¿¼ë¦¬ ì„ë² ë”© (BGE-M3 ì‚¬ìš©)
            q_emb = model.encode([query_text], normalize_embeddings=True, convert_to_numpy=True)
            
            # ìµœëŒ€ kê°’ìœ¼ë¡œ ê²€ìƒ‰ (10ìœ¼ë¡œ ë³€ê²½)
            max_k = 10
            D, I = index.search(q_emb, max_k)
            
            # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ doc_id ì¶”ì¶œ
            retrieved_doc_ids = []
            for idx in I[0]:
                if idx < len(metadata):
                    retrieved_doc_ids.append(metadata[idx]['doc_id'])
            
            # ê° kê°’ì— ëŒ€í•´ Recall ê³„ì‚°
            for k in k_values:
                if gt_doc_id in retrieved_doc_ids[:k]:
                    recalls[f'R@{k}'] += 1
        
        # í‰ê·  Recall ê³„ì‚°
        for k in k_values:
            recalls[f'R@{k}'] /= len(evaluation_queries)
        
        recall_results[index_name] = recalls
        
        # ê²°ê³¼ ì¶œë ¥ - í•œ ì¤„ì— í‘œì‹œ
        recall_str = " | ".join([f"R@{k}: {recalls[f'R@{k}']:.3f}" for k in k_values])
        print(f"   {recall_str}")
    
    return recall_results


def find_best_index(performance_results, recall_results, weights={'recall_5': 0.5, 'qps': 0.3, 'memory': 0.2}):
    """ì¢…í•© ì ìˆ˜ë¡œ ìµœì  ì¸ë±ìŠ¤ ì„ íƒ"""
    
    print("\nğŸ† ì¢…í•© ì„±ëŠ¥ ë¶„ì„")
    print("="*60)
    
    # ì •ê·œí™”ë¥¼ ìœ„í•œ ìµœëŒ€/ìµœì†Œê°’
    max_recall = max([r['R@5'] for r in recall_results.values()])
    max_qps = max([p['qps'] for p in performance_results.values()])
    min_memory = min([p['memory_mb'] for p in performance_results.values()])
    max_memory = max([p['memory_mb'] for p in performance_results.values()])
    
    scores = {}
    
    for name in performance_results.keys():
        recall_5 = recall_results[name]['R@5']
        qps = performance_results[name]['qps']
        memory = performance_results[name]['memory_mb']
        
        # ì •ê·œí™” (0-1 ë²”ìœ„)
        norm_recall = recall_5 / max_recall if max_recall > 0 else 0
        norm_qps = qps / max_qps if max_qps > 0 else 0
        norm_memory = (max_memory - memory) / (max_memory - min_memory) if max_memory > min_memory else 1
        
        # ê°€ì¤‘ ì ìˆ˜ ê³„ì‚°
        total_score = (
            weights['recall_5'] * norm_recall +
            weights['qps'] * norm_qps +
            weights['memory'] * norm_memory
        )
        
        scores[name] = {
            'total_score': total_score,
            'recall_5': recall_5,
            'qps': qps,
            'memory_mb': memory,
            'type': performance_results[name]['type']
        }
    
    # ê²°ê³¼ ì¶œë ¥
    sorted_scores = sorted(scores.items(), key=lambda x: x[1]['total_score'], reverse=True)
    
    print(f"{'Rank':<4} {'Index':<10} {'Score':<6} {'R@5':<6} {'QPS':<8} {'Memory':<10} {'Type'}")
    print("-"*60)
    
    for i, (name, score_info) in enumerate(sorted_scores, 1):
        print(f"{i:<4} {name:<10} {score_info['total_score']:.3f}  "
              f"{score_info['recall_5']:.3f}  {score_info['qps']:<8.1f} "
              f"{score_info['memory_mb']:<10.1f} {score_info['type']}")
    
    best_index = sorted_scores[0][0]
    print(f"\nğŸ¯ ìµœì  ì¸ë±ìŠ¤: {best_index}")
    
    return best_index, scores


def print_detailed_recall_comparison(recall_results):
    """ìƒì„¸í•œ Recall ë¹„êµ í…Œì´ë¸” ì¶œë ¥"""
    print("\nğŸ“Š ìƒì„¸ Recall@K ë¹„êµ ê²°ê³¼")
    print("=" * 100)
    
    # í—¤ë” ì¶œë ¥
    header = "Index    "
    for k in range(1, 11):
        header += f" R@{k:<2}"
    print(header)
    print("-" * 100)
    
    # ê° ì¸ë±ìŠ¤ë³„ ê²°ê³¼ ì¶œë ¥
    for index_name, recalls in recall_results.items():
        row = f"{index_name:<8} "
        for k in range(1, 11):
            recall_value = recalls[f'R@{k}']
            row += f" {recall_value:<4.3f}"
        print(row)
    
    # ìµœê³  ì„±ëŠ¥ í‘œì‹œ
    print("\nğŸ† ê° Kê°’ë³„ ìµœê³  ì„±ëŠ¥:")
    for k in range(1, 11):
        best_recall = max([recalls[f'R@{k}'] for recalls in recall_results.values()])
        best_indexes = [name for name, recalls in recall_results.items() 
                       if recalls[f'R@{k}'] == best_recall]
        print(f"   R@{k}: {best_recall:.3f} ({', '.join(best_indexes)})")


def find_best_index_detailed(performance_results, recall_results, 
                           weights={'recall_1': 0.1, 'recall_3': 0.2, 'recall_5': 0.3, 
                                   'recall_10': 0.2, 'qps': 0.1, 'memory': 0.1}):
    """ë‹¤ì–‘í•œ Recall@Kë¥¼ ê³ ë ¤í•œ ìµœì  ì¸ë±ìŠ¤ ì„ íƒ"""
    
    print("\nğŸ† ì¢…í•© ì„±ëŠ¥ ë¶„ì„ (R@1~10 ê³ ë ¤)")
    print("="*80)
    
    # ì •ê·œí™”ë¥¼ ìœ„í•œ ìµœëŒ€/ìµœì†Œê°’
    max_values = {}
    for k in [1, 3, 5, 10]:
        max_values[f'recall_{k}'] = max([r[f'R@{k}'] for r in recall_results.values()])
    
    max_qps = max([p['qps'] for p in performance_results.values()])
    min_memory = min([p['memory_mb'] for p in performance_results.values()])
    max_memory = max([p['memory_mb'] for p in performance_results.values()])
    
    scores = {}
    
    for name in performance_results.keys():
        # ê° Recall ê°’ë“¤
        r1 = recall_results[name]['R@1']
        r3 = recall_results[name]['R@3']
        r5 = recall_results[name]['R@5']
        r10 = recall_results[name]['R@10']
        
        qps = performance_results[name]['qps']
        memory = performance_results[name]['memory_mb']
        
        # ì •ê·œí™” (0-1 ë²”ìœ„)
        norm_r1 = r1 / max_values['recall_1'] if max_values['recall_1'] > 0 else 0
        norm_r3 = r3 / max_values['recall_3'] if max_values['recall_3'] > 0 else 0
        norm_r5 = r5 / max_values['recall_5'] if max_values['recall_5'] > 0 else 0
        norm_r10 = r10 / max_values['recall_10'] if max_values['recall_10'] > 0 else 0
        norm_qps = qps / max_qps if max_qps > 0 else 0
        norm_memory = (max_memory - memory) / (max_memory - min_memory) if max_memory > min_memory else 1
        
        # ê°€ì¤‘ ì ìˆ˜ ê³„ì‚°
        total_score = (
            weights['recall_1'] * norm_r1 +
            weights['recall_3'] * norm_r3 +
            weights['recall_5'] * norm_r5 +
            weights['recall_10'] * norm_r10 +
            weights['qps'] * norm_qps +
            weights['memory'] * norm_memory
        )
        
        scores[name] = {
            'total_score': total_score,
            'r1': r1, 'r3': r3, 'r5': r5, 'r10': r10,
            'qps': qps, 'memory_mb': memory,
            'type': performance_results[name]['type']
        }
    
    # ê²°ê³¼ ì¶œë ¥
    sorted_scores = sorted(scores.items(), key=lambda x: x[1]['total_score'], reverse=True)
    
    print(f"{'Rank':<4} {'Index':<10} {'Score':<6} {'R@1':<5} {'R@3':<5} {'R@5':<5} {'R@10':<5} {'QPS':<7} {'Memory':<8} {'Type'}")
    print("-"*80)
    
    for i, (name, score_info) in enumerate(sorted_scores, 1):
        print(f"{i:<4} {name:<10} {score_info['total_score']:.3f}  "
              f"{score_info['r1']:<5.3f} {score_info['r3']:<5.3f} "
              f"{score_info['r5']:<5.3f} {score_info['r10']:<5.3f} "
              f"{score_info['qps']:<7.1f} {score_info['memory_mb']:<8.1f} "
              f"{score_info['type']}")
    
    best_index = sorted_scores[0][0]
    print(f"\nğŸ¯ ìµœì  ì¸ë±ìŠ¤: {best_index}")
    
    return best_index, scores





# í•„ìš”í•œ ë°ì´í„° ë¡œë“œ
embeddings = np.load("embeddings.npy")
with open("metadata.pkl", "rb") as f:
    metadata = pickle.load(f)
with open("our_clean_eval_style.jsonl", "r") as f:
    eval_queries = [json.loads(line) for line in f]

# BGE-M3 ëª¨ë¸ ë¡œë“œ
from sentence_transformers import SentenceTransformer
model = SentenceTransformer("BAAI/bge-m3", trust_remote_code=True)

dim = embeddings.shape[1]
n_vectors = embeddings.shape[0]

# í…ŒìŠ¤íŠ¸ìš© ì¿¼ë¦¬ ì„ë² ë”©
np.random.seed(42)
test_query_embeddings = np.random.random((50, dim)).astype('float32')
faiss.normalize_L2(test_query_embeddings)

# ì‹¤í–‰ (k_valuesë¥¼ 1~10ìœ¼ë¡œ í™•ì¥)
print("ğŸš€ FAISS ì¸ë±ìŠ¤ ì„±ëŠ¥ ë¹„êµ ì‹œì‘! (R@1~10)")

# 1. ì¸ë±ìŠ¤ ìƒì„±
indexes = create_multiple_indexes(embeddings)

# 2. ì†ë„ ë²¤ì¹˜ë§ˆí¬
performance_results = benchmark_indexes(indexes, test_query_embeddings)

# 3. Recall ì •í™•ë„ ì¸¡ì • (R@1~10)
recall_results = measure_recall_accuracy(indexes, eval_queries, metadata, model, 
                                       k_values=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])

# 4. ìƒì„¸ ê²°ê³¼ ì¶œë ¥
print_detailed_recall_comparison(recall_results)

# 5. ìµœì  ì¸ë±ìŠ¤ ì„ íƒ (ë‹¤ì–‘í•œ Recall ê³ ë ¤)
best_index, all_scores = find_best_index_detailed(performance_results, recall_results)

# 6. ìµœì  ì¸ë±ìŠ¤ ì €ì¥
print(f"\nğŸ’¾ ìµœì  ì¸ë±ìŠ¤ ({best_index}) ì €ì¥ ì¤‘...")
faiss.write_index(indexes[best_index]['index'], f"best_{best_index.lower()}.index")
print(f"âœ… ì €ì¥ ì™„ë£Œ: best_{best_index.lower()}.index")

for name, index_info in indexes.items():
    filename = f"{name.lower()}_index.faiss"
    faiss.write_index(index_info['index'], filename)
    print(f"âœ… {name} ì €ì¥: {filename}")